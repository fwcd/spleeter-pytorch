#!/usr/bin/env python3

# A script for converting the Spleeter separator to Core ML.

# Useful resources:
# - https://github.com/deezer/spleeter/issues/210
# - https://github.com/deezer/spleeter/issues/155
# - https://twitter.com/ExtractorVocal/status/1342643493227773952

import argparse
import coremltools as ct
import librosa
import torch

from pathlib import Path
from spleeter_pytorch.estimator import Estimator

ROOT = Path(__file__).resolve().parent

def main():
    parser = argparse.ArgumentParser(description='Converts Spleeter (minus the STFT preprocessing) to Core ML')
    parser.add_argument('-o', '--output', type=Path, default=ROOT / 'output' / 'coreml', help='The output directory to place the model in')

    args = parser.parse_args()

    samplerate = 44100
    estimator = Estimator(2, ROOT / 'checkpoints' / '2stems' / 'model')
    estimator.eval()

    # Load wav audio
    wav, _ = librosa.load(ROOT / 'audio_example.mp3', mono=False, res_type='kaiser_fast', sr=samplerate)
    wav = torch.Tensor(wav)

    # Reproduce the STFT step (which we cannot convert to Core ML, unfortunately)
    _, stft_mag = estimator.compute_stft(wav)

    print('==> Tracing')
    traced_model = torch.jit.trace(estimator.separator, stft_mag)
    out = traced_model(stft_mag)

    print('==> Converting') # TODO: Dynamic input size?
    mlmodel = ct.convert(traced_model, convert_to='mlprogram', inputs=[ct.TensorType(shape=stft_mag.shape)])

    print('==> Writing')
    output: Path = args.output
    output.mkdir(parents=True, exist_ok=True)
    mlmodel.save(output / 'Spleeter.mlpackage')

if __name__ == '__main__':
    main()
